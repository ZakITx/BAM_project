{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.inspection import permutation_importance\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "#Classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Decomposition\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.read_excel('/Users/azmanizakary/Downloads/Integrated_Data_BAM.xlsx', sheet_name=None, header=0)\n",
    "for sheet in xlsx.keys(): xlsx[sheet].to_excel(sheet+'.xlsx', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in xlsx.keys():\n",
    "    print(key, ':\\n', xlsx[key].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in xlsx.keys():\n",
    "    xlsx[key].replace('--', np.nan, inplace=True)\n",
    "    print(key, ':\\n', xlsx[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in xlsx.keys() - {'uk_home_retail'}:\n",
    "    columns_to_fill = xlsx[key].columns[1:]\n",
    "    \n",
    "    # Calculate the median for the selected columns\n",
    "    median_values = xlsx[key][columns_to_fill].median()\n",
    "    \n",
    "    # Fill NaN values with the median\n",
    "    xlsx[key][columns_to_fill] = xlsx[key][columns_to_fill].fillna(median_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx['uk_home_retail'] = xlsx['uk_home_retail'].drop('UK Home Sales', axis=1)\n",
    "xlsx['uk_home_retail'] = xlsx['uk_home_retail'].dropna(axis=1)\n",
    "xlsx['construction_cost_prices_sales'] = xlsx['construction_cost_prices_sales'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "keys_q_only = [\n",
    "    key for key in xlsx.keys()\n",
    "    if not xlsx[key].empty  # Vérifie que le DataFrame n'est pas vide\n",
    "    and xlsx[key].shape[1] > 0  # Vérifie qu'il a au moins une colonne\n",
    "    and xlsx[key][xlsx[key].columns[0]].astype(str)  # Convertit en str\n",
    "        .str.match(r'^Q', na=False)  # Vérifie que toutes les valeurs commencent par \"Q\"\n",
    "        .all()  # S'assure que c'est vrai pour toute la colonne\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in xlsx.keys() - set(keys_q_only):\n",
    "    xlsx[key][xlsx[key].columns[0]] = pd.to_datetime(xlsx[key][xlsx[key].columns[0]], errors='coerce')\n",
    "    \n",
    "for key in keys_q_only:\n",
    "    # Extraction du Quarter et de l'Année\n",
    "    xlsx[key][xlsx[key].columns[0]] = pd.to_datetime(xlsx[key][xlsx[key].columns[0]].str[-4:] + xlsx[key][xlsx[key].columns[0]].str[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_snake_case(col_name):\n",
    "    col_name = re.sub(r'([a-z])([A-Z])', r'\\1_\\2', col_name)  # Convert camelCase/PascalCase to snake_case\n",
    "    col_name = re.sub(r'\\W+', '_', col_name)  # Replace non-word characters (spaces, special chars) with \"_\"\n",
    "    col_name = re.sub(r'__+', '_', col_name)  # Replace multiple \"_\" with a single \"_\"\n",
    "    return col_name.lower().strip('_')  # Convert to lowercase and remove leading/trailing \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in xlsx.keys():\n",
    "    xlsx[key].columns = [to_snake_case(xlsx[key].columns[0])] + [f\"{key}.{to_snake_case(col)}\" for col in xlsx[key].columns[1:]]\n",
    "    xlsx[key] = xlsx[key].rename(columns={'yymm': 'date', 'revenues': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicated time samples\n",
    "xlsx['uk_home_retail'] = xlsx['uk_home_retail'].sort_values('date', ascending=False).drop_duplicates('date').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in xlsx.keys():\n",
    "    xlsx[key] = xlsx[key].sort_values('date', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the data into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_trimestrielle(df):\n",
    "    df_expanded = pd.DataFrame()\n",
    "    for _, row in df.iterrows():\n",
    "        # Créer 3 mois à partir de la date du trimestre\n",
    "        months = pd.date_range(start=row['date'], periods=3, freq='ME')\n",
    "        expanded = pd.DataFrame([row.to_dict()] * 3)\n",
    "        expanded['date'] = months\n",
    "        df_expanded = pd.concat([df_expanded, expanded], ignore_index=True)\n",
    "    return df_expanded\n",
    "\n",
    "def reformat_annuelle(df):\n",
    "    df_expanded = pd.DataFrame()\n",
    "    for _, row in df.iterrows():\n",
    "        # Créer 12 mois à partir de la date annuelle\n",
    "        months = pd.date_range(start=row['date'], periods=12, freq='ME')\n",
    "        expanded = pd.DataFrame([row.to_dict()] * 12)\n",
    "        expanded['date'] = months\n",
    "        df_expanded = pd.concat([df_expanded, expanded], ignore_index=True)\n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(xlsx):\n",
    "    result = pd.DataFrame()\n",
    "    data_frames = []\n",
    "    for sheet_name, df in xlsx.items():\n",
    "\n",
    "        # Identifier la granularité des données\n",
    "        freq = pd.infer_freq(df['date'].sort_values())\n",
    "\n",
    "        if 'Y' in freq:  # Données annuelles\n",
    "            df_processed = reformat_annuelle(df)\n",
    "        elif 'Q' in freq:  # Données trimestrielles\n",
    "            df_processed = reformat_trimestrielle(df)\n",
    "        elif 'MS' in freq:  # Données mensuelles (aucune duplication)\n",
    "            df_processed = df.copy()\n",
    "        data_frames.append(df)\n",
    "\n",
    "    result = reduce(lambda  left,right: pd.merge(left,right,on=['date'],\n",
    "                                            how='outer'), data_frames).bfill()\n",
    "    result = result.ffill()\n",
    "    \n",
    "    result['year'] = result['date'].dt.year\n",
    "    result['month'] = result['date'].dt.month\n",
    "    result['day'] = result['date'].dt.day\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement des données\n",
    "df_final = process_data(xlsx)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unemployment rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final[['year', 'month', 'unemployment_rate.population']]\n",
    "y = df_final['unemployment_rate.unenployment_rate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Intercept: \", model.intercept_)\n",
    "print(\"Coefficients:\")\n",
    "list(zip(X.columns, model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mlr_diff = pd.DataFrame({'Actual value': y_test, 'Predicted value': y_pred})\n",
    "mlr_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résidus\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Graphique des résidus\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Valeurs prédites\")\n",
    "plt.ylabel(\"Résidus\")\n",
    "plt.title(\"Résidus vs Valeurs prédites\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "bp_test = het_breuschpagan(residuals, X_test_sm)\n",
    "\n",
    "# Résultats\n",
    "labels = ['Statistique LM', 'p-value', 'F-statistique', 'p-value F']\n",
    "print(dict(zip(labels, bp_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Distribution des résidus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vif = sm.add_constant(X)  # Ajout de la constante\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i+1) for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R²:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Intercept: \", model.intercept_)\n",
    "    print(\"Coefficients:\")\n",
    "    print(list(zip(X.columns, model.coef_)))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    meanAbErr = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    meanSqErr = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print('R^2: {:.2f}'.format(r2_score(y_test, y_pred)))\n",
    "\n",
    "    #Mean Absolute Error is the absolute difference between the true values and the predicted values.\n",
    "    #The lower the value, the better is the model’s performance.\n",
    "    print('Mean Absolute Error:', meanAbErr)\n",
    "\n",
    "    #Mean Square Error is calculated by taking the average of the square of the difference between the original and predicted values of the data.\n",
    "    #The lower the value, the better is the model’s performance.\n",
    "    print('Mean Square Error:', meanSqErr)\n",
    "\n",
    "    #Root Mean Square Error is the standard deviation of the errors which occur when a prediction is made on a dataset. \n",
    "    #The root of the value is considered while determining the accuracy of the model.\n",
    "    print('Root Mean Square Error:', rootMeanSqErr)\n",
    "    \n",
    "    return {'model': model, 'y_test': y_test, 'y_pred': y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in xlsx['company_revenue'].columns[1:]:\n",
    "    y = df_final[name]\n",
    "\n",
    "    L = list(xlsx['gov_total_expense_revenue'].columns)\n",
    "    L.append('year')\n",
    "    L.append('month')\n",
    "    L.append('day')\n",
    "\n",
    "\n",
    "    X = df_final[L]\n",
    "    X = X.drop('date', axis=1)\n",
    "    X = X.drop('gov_total_expense_revenue.surplus_or_deficit', axis=1)\n",
    "\n",
    "    test = linear_regression(X, y)\n",
    "\n",
    "    # Résidus\n",
    "    residuals = test['y_pred'] - test['y_test']\n",
    "\n",
    "\n",
    "    # Graphique des résidus\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=test['y_pred'], y=residuals)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel(\"Valeurs prédites\")\n",
    "    plt.ylabel(\"Résidus\")\n",
    "    plt.title(\"Résidus vs Valeurs prédites\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "def run_regression(df, dependent_var, independent_vars, independent_file):\n",
    "    # Suppression du préfixe pour la variable dépendante\n",
    "    dep_var_clean = dependent_var.split('.')[-1]\n",
    "\n",
    "\n",
    "    X = df[[f\"{independent_file}.{var}\" for var in independent_vars[1:]]]\n",
    "\n",
    "    # Ajout de la colonne 'year' qui n'a pas de préfixe\n",
    "    X.loc[:, 'year'] = df[independent_vars[0]]\n",
    "\n",
    "    new_col_names = [col.split('.')[-1] for col in independent_vars]\n",
    "    X.columns = new_col_names\n",
    "\n",
    "    # Extraction de la variable dépendante\n",
    "    y = df[dependent_var]\n",
    "\n",
    "    # Fusion des données\n",
    "    df_model = X.join(y)\n",
    "    df_model.columns = new_col_names + [dep_var_clean]\n",
    "\n",
    "    # Construction de la formule de régression\n",
    "    formula = f\"{dep_var_clean} ~ {' + '.join(new_col_names)}\"\n",
    "\n",
    "    # Modélisation\n",
    "    model = smf.ols(formula=formula, data=df_model).fit()\n",
    "\n",
    "    return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_regression(\n",
    "    df=df_final,\n",
    "    dependent_var='company_revenue.speedy_hire_plc_sdy_l',\n",
    "    independent_vars=['year', 'gbp_to_usd_exchange_rate', 'economic_growth_rate'],\n",
    "    independent_file='economic_growth'\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_analysis(df, dependent_var, independent_vars, show_feature_importance=False):\n",
    "    results = []\n",
    "    feature_importance_results = {}\n",
    "\n",
    "    # Préparation des données\n",
    "    X = df[independent_vars].copy()\n",
    "    y = df[dependent_var].copy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Test de normalité\n",
    "    p_values = [shapiro(X_train[col])[1] for col in X_train.columns]\n",
    "    p_value_y = shapiro(y_train)[1]\n",
    "    normality_verified = all(p > 0.05 for p in p_values) and p_value_y > 0.05\n",
    "\n",
    "    # Application du scaler\n",
    "    scaler_X = StandardScaler() if normality_verified else MinMaxScaler()\n",
    "    scaler_y = StandardScaler() if normality_verified else MinMaxScaler()\n",
    "\n",
    "    print(\"Data is standardized\" if normality_verified else \"Data is normalized\")\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "    y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Modèles à évaluer\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "        'Support Vector Regressor': SVR(),\n",
    "        'MLP Regressor': MLPRegressor(random_state=42, max_iter=1000)\n",
    "    }\n",
    "\n",
    "    # KNN avec k variant de 1 à 10\n",
    "    for k in range(1, 11):\n",
    "        models[f'KNN (k={k})'] = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "        # Prédictions (scalées)\n",
    "        y_pred_train_scaled = model.predict(X_train_scaled)\n",
    "        y_pred_test_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "        # Inversion du scaling pour les prédictions\n",
    "        y_pred_train = scaler_y.inverse_transform(y_pred_train_scaled.reshape(-1, 1)).flatten()\n",
    "        y_pred_test = scaler_y.inverse_transform(y_pred_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Calcul des métriques\n",
    "        mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "        # Importance des features\n",
    "        if hasattr(model, \"coef_\"):  # Modèles linéaires\n",
    "            importance = model.coef_.flatten()\n",
    "            feature_names = independent_vars\n",
    "\n",
    "        elif hasattr(model, \"feature_importances_\"):  # Arbres de décision\n",
    "            importance = model.feature_importances_\n",
    "            feature_names = independent_vars\n",
    "\n",
    "        else:  # Autres modèles (SVR, KNN, MLP)\n",
    "            perm_importance = permutation_importance(model, X_test_scaled, y_test_scaled, n_repeats=10, random_state=42)\n",
    "            importance = perm_importance.importances_mean\n",
    "            feature_names = X.columns\n",
    "\n",
    "        # Vérification des dimensions\n",
    "        if len(importance) == len(feature_names):\n",
    "            feature_importance_results[model_name] = pd.Series(importance, index=feature_names).sort_values(ascending=False)\n",
    "        else:\n",
    "            print(f\"⚠️ Dimension mismatch for {model_name}: {len(importance)} importances vs {len(feature_names)} features\")\n",
    "            feature_importance_results[model_name] = pd.Series(importance[:len(feature_names)], index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "        # Tests statistiques pour la régression linéaire uniquement\n",
    "        if model_name == \"Linear Regression\":\n",
    "            X_const = add_constant(X_train_scaled)\n",
    "            ols_model = OLS(y_train_scaled, X_const).fit()\n",
    "\n",
    "            r2 = ols_model.rsquared_adj\n",
    "            shapiro_test = shapiro(ols_model.resid)\n",
    "            bp_test = het_breuschpagan(ols_model.resid, X_const)\n",
    "            dw_test = durbin_watson(ols_model.resid)\n",
    "\n",
    "        else:\n",
    "            r2 = r2_score(y_test, y_pred_test)\n",
    "            shapiro_test = (np.nan, np.nan)\n",
    "            bp_test = (np.nan, np.nan, np.nan, np.nan)\n",
    "            dw_test = np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            'MAE Train': mae_train,\n",
    "            'MAE Test': mae_test,\n",
    "            'R² Test': r2,\n",
    "            \"Shapiro-W (p-value)\": shapiro_test[1],\n",
    "            \"Breusch-Pagan (p-value)\": bp_test[3],\n",
    "            \"Durbin-Watson\": dw_test\n",
    "        })\n",
    "\n",
    "    # Conversion en DataFrame pour analyse\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if show_feature_importance:\n",
    "        for model, importance in feature_importance_results.items():\n",
    "            print(f\"\\n🔍 Top 10 Features for {model}:\")\n",
    "            print(importance.head(10))\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_pipeline(df, dependent_var, independent_vars):\n",
    "    # Préparation des données\n",
    "    X = df[independent_vars]\n",
    "    y = df[dependent_var]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Test de normalité sur X_train\n",
    "    _, p_value_train = shapiro(X_train)\n",
    "    \n",
    "    # Application du scaler en fonction du test de normalité\n",
    "    if p_value_train > 0.05:  # Normalité vérifiée\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        print(\"Data is standardised\")\n",
    "        \n",
    "    else:  # Normalité non vérifiée\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        print(\"Data is normalized\")\n",
    "\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge Regression\": Ridge(),\n",
    "        \"Lasso Regression\": Lasso(),\n",
    "        \"KNN Regression\": KNeighborsRegressor(),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "                \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Tests statistiques pour la régression linéaire uniquement\n",
    "        if name == \"Linear Regression\":\n",
    "            X_const = add_constant(X_train_scaled)\n",
    "            ols_model = OLS(y_train, X_const).fit()\n",
    "\n",
    "            # Adjusted R-squared\n",
    "            r2 = ols_model.rsquared_adj\n",
    "\n",
    "            # Test de normalité des résidus\n",
    "            shapiro_test = shapiro(ols_model.resid)\n",
    "\n",
    "            # Test de Breusch-Pagan pour l'homoscédasticité\n",
    "            bp_test = het_breuschpagan(ols_model.resid, X_const)\n",
    "\n",
    "            # Test de Durbin-Watson pour l'autocorrélation\n",
    "            dw_test = durbin_watson(ols_model.resid)\n",
    "\n",
    "        else:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            shapiro_test = (np.nan, np.nan)\n",
    "            bp_test = (np.nan, np.nan, np.nan, np.nan)\n",
    "            dw_test = np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"R²\": r2,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"Shapiro-W (p-value)\": shapiro_test[1],\n",
    "            \"Breusch-Pagan (p-value)\": bp_test[3],\n",
    "            \"Durbin-Watson\": dw_test\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars = list(df_final[xlsx['company_revenue'].columns[1:]])\n",
    "independent_vars = list(xlsx['bonds'].columns[1:])\n",
    "independent_vars.append('year')\n",
    "df = df_final[dependent_vars +independent_vars].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(xlsx['unemployment_rate'].columns[1:]) \n",
    "X += list(xlsx['extra_unemployment_rate'].columns[3:5])\n",
    "X.append(xlsx['gov_total_expense_revenue'].columns[3])\n",
    "X += list(xlsx['money_supply'].columns[1:])\n",
    "X += list(xlsx['bonds'].columns[1:])\n",
    "X += list(xlsx['cpi'].columns[1:])\n",
    "X += list(xlsx['economic_growth'].columns[1:])\n",
    "X += list(xlsx['import_export'].columns[1:])\n",
    "X += list(xlsx['seasonal_retail_sales'].columns[1:])\n",
    "#X += list(xlsx['uk_home_retail'].columns[1:]) too many columns\n",
    "X += list(xlsx['uk_building'].columns[1:])\n",
    "#X += list(xlsx['uk_affordability_index'].columns[1:]) too many columns\n",
    "X += list(xlsx['uk_retail_price'].columns[1:])\n",
    "X += list(xlsx['mortage'].columns[1:])\n",
    "X += list(xlsx['mortage_interest_rate'].columns[1:])\n",
    "X.append(xlsx['construction_cost_prices_sales'].columns[1])\n",
    "X += list(xlsx['construction_cost_prices_sales'].columns[3:5])\n",
    "X += list(xlsx['construction_cost_prices_sales'].columns[6:])\n",
    "X.append('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final[dependent_vars + X].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_analysis(df, dependent_var, independent_vars, show_feature_importance=False):\n",
    "    results = []\n",
    "    feature_importance_results = {}\n",
    "    best_models = {}  # Stockage des meilleurs modèles\n",
    "\n",
    "    # Préparation des données\n",
    "    X = df[independent_vars].copy()\n",
    "    y = df[dependent_var].copy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Test de normalité\n",
    "    p_values = [shapiro(X_train[col])[1] for col in X_train.columns]\n",
    "    normality_verified = all(p > 0.05 for p in p_values)\n",
    "\n",
    "    # Application du scaler\n",
    "    scaler = StandardScaler() if normality_verified else MinMaxScaler()\n",
    "    print(\"Data is standardized\" if normality_verified else \"Data is normalized\")\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Modèles à évaluer\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "        'Support Vector Regressor': SVR(),\n",
    "        #'MLP Regressor': MLPRegressor(random_state=42, max_iter=1000)\n",
    "    }\n",
    "\n",
    "    # KNN avec k variant de 1 à 10\n",
    "    for k in range(3, 11):\n",
    "        models[f'KNN (k={k})'] = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Prédictions\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "        # Importance des features\n",
    "        if hasattr(model, \"coef_\"):  # Modèles linéaires\n",
    "            importance = model.coef_.flatten()\n",
    "            feature_names = independent_vars\n",
    "        elif hasattr(model, \"feature_importances_\"):  # Arbres de décision\n",
    "            importance = model.feature_importances_\n",
    "            feature_names = independent_vars\n",
    "        else:  # Autres modèles (SVR, KNN, MLP)\n",
    "            perm_importance = permutation_importance(model, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "            importance = perm_importance.importances_mean\n",
    "            feature_names = X.columns\n",
    "\n",
    "        # Vérification des dimensions\n",
    "        if len(importance) == len(feature_names):\n",
    "            feature_importance_results[model_name] = pd.Series(importance, index=feature_names).sort_values(ascending=False)\n",
    "        else:\n",
    "            print(f\"⚠️ Dimension mismatch for {model_name}: {len(importance)} importances vs {len(feature_names)} features\")\n",
    "            feature_importance_results[model_name] = pd.Series(importance[:len(feature_names)], index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "        # Tests statistiques pour la régression linéaire uniquement\n",
    "        if model_name == \"Linear Regression\":\n",
    "            X_const = add_constant(X_train_scaled)\n",
    "            ols_model = OLS(y_train, X_const).fit()\n",
    "\n",
    "            r2 = ols_model.rsquared_adj\n",
    "            shapiro_test = shapiro(ols_model.resid)\n",
    "            bp_test = het_breuschpagan(ols_model.resid, X_const)\n",
    "            dw_test = durbin_watson(ols_model.resid)\n",
    "        else:\n",
    "            r2 = r2_score(y_test, y_pred_test)\n",
    "            shapiro_test = (np.nan, np.nan)\n",
    "            bp_test = (np.nan, np.nan, np.nan, np.nan)\n",
    "            dw_test = np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            'MAE Train': mae_train,\n",
    "            'MAE Test': mae_test,\n",
    "            'R² Test': r2,\n",
    "            \"Shapiro-W (p-value)\": shapiro_test[1],\n",
    "            \"Breusch-Pagan (p-value)\": bp_test[3],\n",
    "            \"Durbin-Watson\": dw_test\n",
    "        })\n",
    "\n",
    "    # Sélection du meilleur modèle (basé sur MAE Test et R²)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best_model_row = results_df.sort_values(by=['MAE Test', 'R² Test'], ascending=[True, False]).iloc[0]\n",
    "    best_model_name = best_model_row['Model']\n",
    "    best_models[dependent_var] = {\n",
    "        \"Model\": best_model_name,\n",
    "        \"MAE Train\": best_model_row['MAE Train'],\n",
    "        \"MAE Test\": best_model_row['MAE Test'],\n",
    "        \"R² Test\": best_model_row['R² Test'],\n",
    "        \"Top Features\": feature_importance_results[best_model_name].head(10)\n",
    "    }\n",
    "\n",
    "    if show_feature_importance:\n",
    "        for model, importance in feature_importance_results.items():\n",
    "            print(f\"\\n🔍 Top 10 Features for {model}:\")\n",
    "            print(importance.head(10))\n",
    "\n",
    "    return results_df, best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenues prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: company_revenue.speedy_hire_plc_sdy_l\n",
      "  (                       Model  MAE Train   MAE Test   R² Test  \\\n",
      "0          Linear Regression   3.877175  11.164484  0.885778   \n",
      "1              Random Forest   2.452950   9.253837  0.741999   \n",
      "2          Gradient Boosting   1.492737   8.008315  0.757074   \n",
      "3   Support Vector Regressor  12.125114  21.001732  0.261103   \n",
      "4                  KNN (k=3)   2.710307   9.314530  0.679642   \n",
      "5                  KNN (k=4)   3.107895   9.784615  0.658962   \n",
      "6                  KNN (k=5)   3.659474  10.349744  0.644053   \n",
      "7                  KNN (k=6)   4.114254  11.217094  0.641233   \n",
      "8                  KNN (k=7)   4.320113  10.970696  0.649528   \n",
      "9                  KNN (k=8)   4.720806  11.518590  0.637609   \n",
      "10                 KNN (k=9)   5.291667  11.769801  0.631151   \n",
      "11                KNN (k=10)   5.721053  11.755385  0.662547   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          3.260848e-10             2.978892e-11       2.199227  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'company_revenue.speedy_hire_plc_sdy_l': {'Model': 'Gradient Boosting', 'MAE Train': 1.492736631765129, 'MAE Test': 8.008314955330729, 'R² Test': 0.7570740226826373, 'Top Features': cpi.cpi                                                   0.239000\n",
      "cpi.cpi_annual_growth_rate                                0.106298\n",
      "mortage.house_purchase                                    0.095880\n",
      "construction_cost_prices_sales.infrastructure2            0.075742\n",
      "mortage.monetary_financial_institutions                   0.073703\n",
      "mortage_interest_rate.2_years                             0.068283\n",
      "uk_retail_price.index_of_private_housing_rental_prices    0.048921\n",
      "uk_retail_price.east                                      0.044355\n",
      "construction_cost_prices_sales.housing                    0.041177\n",
      "extra_unemployment_rate.male                              0.033856\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: company_revenue.terex_corp_tex\n",
      "  (                       Model    MAE Train    MAE Test   R² Test  \\\n",
      "0          Linear Regression    75.077182  403.013743  0.986776   \n",
      "1              Random Forest    37.512499  278.159949  0.741372   \n",
      "2          Gradient Boosting    23.656643  265.953353  0.745084   \n",
      "3   Support Vector Regressor  1233.210659  995.554284 -0.020356   \n",
      "4                  KNN (k=3)    51.947368  301.401709  0.697327   \n",
      "5                  KNN (k=4)    57.861020  318.709615  0.675364   \n",
      "6                  KNN (k=5)    67.439079  329.165128  0.663966   \n",
      "7                  KNN (k=6)    78.644737  346.064103  0.670409   \n",
      "8                  KNN (k=7)    84.847744  339.403663  0.681520   \n",
      "9                  KNN (k=8)    95.380016  347.875641  0.673273   \n",
      "10                 KNN (k=9)   104.904459  349.816239  0.678217   \n",
      "11                KNN (k=10)   115.429934  337.846667  0.726339   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          1.686161e-11             9.810557e-25       1.844989  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'company_revenue.terex_corp_tex': {'Model': 'Gradient Boosting', 'MAE Train': 23.65664292854305, 'MAE Test': 265.95335321817475, 'R² Test': 0.7450835748948768, 'Top Features': unemployment_rate.unenployment_rate                       0.593624\n",
      "money_supply.m1                                           0.211044\n",
      "mortage_interest_rate.5_years3                            0.059294\n",
      "money_supply.m2                                           0.048468\n",
      "cpi.cpi                                                   0.037447\n",
      "money_supply.m3                                           0.009833\n",
      "uk_retail_price.wales                                     0.006423\n",
      "uk_retail_price.index_of_private_housing_rental_prices    0.004789\n",
      "money_supply.m4_yoy_growth_rate                           0.003357\n",
      "uk_retail_price.south_west_england                        0.002950\n",
      "dtype: float64}})\n"
     ]
    }
   ],
   "source": [
    "for i in dependent_vars:\n",
    "    resultats = regression_analysis(df, i, X)\n",
    "    print(f'y: {i}\\n ', resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars = list(df_final[xlsx['operating_expenses'].columns[1:]])\n",
    "df = df_final[dependent_vars + X].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.ashtead_group_plc_aht_l\n",
      "  (                       Model    MAE Train     MAE Test   R² Test  \\\n",
      "0          Linear Regression    63.429908   201.211474  0.994555   \n",
      "1              Random Forest    35.763853   102.898435  0.989061   \n",
      "2          Gradient Boosting    17.299989    99.205038  0.986845   \n",
      "3   Support Vector Regressor  1516.470244  1605.577114 -0.076997   \n",
      "4                  KNN (k=3)    44.954605    93.638462  0.990340   \n",
      "5                  KNN (k=4)    53.506579   107.426282  0.988924   \n",
      "6                  KNN (k=5)    63.995395   113.209231  0.988389   \n",
      "7                  KNN (k=6)    75.749123   136.854274  0.987199   \n",
      "8                  KNN (k=7)    81.258177   134.480952  0.987475   \n",
      "9                  KNN (k=8)    92.239391   144.050962  0.986458   \n",
      "10                 KNN (k=9)   104.404751   143.755271  0.986456   \n",
      "11                KNN (k=10)   114.796118   144.124615  0.986903   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          8.689669e-10             1.505970e-09       1.996249  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.ashtead_group_plc_aht_l': {'Model': 'KNN (k=3)', 'MAE Train': 44.954605263158, 'MAE Test': 93.63846153846164, 'R² Test': 0.9903396940361504, 'Top Features': construction_cost_prices_sales.public_and_housing_associations    0.002083\n",
      "uk_retail_price.london                                            0.001802\n",
      "uk_retail_price.england                                           0.001802\n",
      "uk_retail_price.index_of_private_housing_rental_prices            0.001802\n",
      "uk_retail_price.south_east_england                                0.001785\n",
      "uk_retail_price.wales                                             0.001785\n",
      "uk_building.building_housing_starts                               0.001768\n",
      "mortage_interest_rate.2_years5                                    0.001768\n",
      "uk_retail_price.scotland                                          0.001734\n",
      "mortage_interest_rate.standard_variable_rate                      0.001717\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.babcock_international_group_plc_bab_l\n",
      "  (                       Model   MAE Train    MAE Test   R² Test  \\\n",
      "0          Linear Regression   21.886391   61.592385  0.948778   \n",
      "1              Random Forest    8.307942   30.181486  0.905356   \n",
      "2          Gradient Boosting    5.723430   27.468470  0.910674   \n",
      "3   Support Vector Regressor  175.955756  155.675873  0.091067   \n",
      "4                  KNN (k=3)    9.301096   33.979487  0.882647   \n",
      "5                  KNN (k=4)   11.554934   35.632051  0.882764   \n",
      "6                  KNN (k=5)   13.194474   38.909744  0.862523   \n",
      "7                  KNN (k=6)   15.251754   39.590171  0.873420   \n",
      "8                  KNN (k=7)   15.899248   37.784982  0.882345   \n",
      "9                  KNN (k=8)   17.777549   37.707692  0.884716   \n",
      "10                 KNN (k=9)   19.085965   36.459829  0.888957   \n",
      "11                KNN (k=10)   20.384342   35.893077  0.902629   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          1.191252e-12                  0.00075       1.898894  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.babcock_international_group_plc_bab_l': {'Model': 'Gradient Boosting', 'MAE Train': 5.723430077263692, 'MAE Test': 27.468470454431845, 'R² Test': 0.9106742973232665, 'Top Features': cpi.cpi                                           0.483181\n",
      "money_supply.m3                                   0.267072\n",
      "money_supply.m1                                   0.129428\n",
      "uk_retail_price.scotland                          0.051118\n",
      "money_supply.m2                                   0.009255\n",
      "unemployment_rate.unenployment_rate               0.008579\n",
      "uk_retail_price.south_west_england                0.005524\n",
      "mortage_interest_rate.5_years3                    0.004982\n",
      "seasonal_retail_sales.retail_sale_volume_index    0.004832\n",
      "import_export.import                              0.004131\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.column1\n",
      "  (                       Model   MAE Train    MAE Test   R² Test  \\\n",
      "0          Linear Regression   32.117550  101.776884  0.942629   \n",
      "1              Random Forest   20.352922   44.604414  0.935995   \n",
      "2          Gradient Boosting   12.104753   43.327121  0.923002   \n",
      "3   Support Vector Regressor  204.710040  213.713613  0.048658   \n",
      "4                  KNN (k=3)   22.635965   36.213675  0.950195   \n",
      "5                  KNN (k=4)   26.398026   43.660256  0.935050   \n",
      "6                  KNN (k=5)   32.513158   46.276923  0.932133   \n",
      "7                  KNN (k=6)   39.392544   60.282051  0.910549   \n",
      "8                  KNN (k=7)   41.122180   61.787546  0.906516   \n",
      "9                  KNN (k=8)   43.274671   65.817308  0.894733   \n",
      "10                 KNN (k=9)   47.323830   64.054131  0.900357   \n",
      "11                KNN (k=10)   50.950658   63.876923  0.906178   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          5.013915e-14             3.601518e-07       2.014389  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.column1': {'Model': 'KNN (k=3)', 'MAE Train': 22.6359649122807, 'MAE Test': 36.21367521367521, 'R² Test': 0.950195278031585, 'Top Features': construction_cost_prices_sales.public_and_housing_associations    0.025866\n",
      "uk_retail_price.south_west_england                                0.022138\n",
      "uk_building.local_authorities                                     0.019033\n",
      "uk_retail_price.london                                            0.018487\n",
      "uk_retail_price.england                                           0.018487\n",
      "uk_retail_price.index_of_private_housing_rental_prices            0.018487\n",
      "uk_retail_price.south_east_england                                0.017264\n",
      "uk_retail_price.wales                                             0.017264\n",
      "uk_retail_price.yorkshire_and_humberside                          0.017249\n",
      "mortage_interest_rate.2_years5                                    0.016042\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.caterpillar_inc_cat\n",
      "  (                       Model    MAE Train     MAE Test   R² Test  \\\n",
      "0          Linear Regression   616.807245  2062.771553  0.944218   \n",
      "1              Random Forest   403.258341  1555.488829  0.640525   \n",
      "2          Gradient Boosting   219.293135  1591.418070  0.559817   \n",
      "3   Support Vector Regressor  5017.777691  4638.680729 -0.446472   \n",
      "4                  KNN (k=3)   421.188596  1586.726496  0.602940   \n",
      "5                  KNN (k=4)   496.988487  1706.301282  0.571659   \n",
      "6                  KNN (k=5)   563.581579  1771.928205  0.558025   \n",
      "7                  KNN (k=6)   651.901316  1886.709402  0.562502   \n",
      "8                  KNN (k=7)   689.515038  1823.714286  0.580295   \n",
      "9                  KNN (k=8)   772.501645  1843.240385  0.574831   \n",
      "10                 KNN (k=9)   856.060673  1829.461538  0.579914   \n",
      "11                KNN (k=10)   928.663158  1775.610256  0.639773   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          3.817324e-11             1.381196e-14       1.956885  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.caterpillar_inc_cat': {'Model': 'Random Forest', 'MAE Train': 403.25834069548864, 'MAE Test': 1555.488829059829, 'R² Test': 0.6405247498543851, 'Top Features': bonds.20_year                                                     0.687361\n",
      "bonds.10_year                                                     0.058283\n",
      "money_supply.m3_yoy_growth_rate                                   0.044292\n",
      "construction_cost_prices_sales.public_and_housing_associations    0.042307\n",
      "unemployment_rate.unenployment_rate                               0.018982\n",
      "construction_cost_prices_sales.private_industrial                 0.015419\n",
      "extra_unemployment_rate.female                                    0.013207\n",
      "uk_retail_price.wales                                             0.011951\n",
      "money_supply.m2_yoy_growth_rate                                   0.011598\n",
      "construction_cost_prices_sales.housing                            0.011429\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.hitachi_construction_machinery_co_ltd_6305_t\n",
      "  (                       Model      MAE Train       MAE Test   R² Test  \\\n",
      "0          Linear Regression   10927.068502   27885.712874  0.982082   \n",
      "1              Random Forest    6281.033112   17116.852980  0.960216   \n",
      "2          Gradient Boosting    2831.968516   16210.709503  0.946363   \n",
      "3   Support Vector Regressor  120157.782351  135509.608967 -0.333292   \n",
      "4                  KNN (k=3)    7034.168860   13727.495726  0.960603   \n",
      "5                  KNN (k=4)    8350.975329   15844.647436  0.956393   \n",
      "6                  KNN (k=5)    9932.607895   16462.958974  0.956398   \n",
      "7                  KNN (k=6)   11712.696272   20495.884615  0.952332   \n",
      "8                  KNN (k=7)   12697.628759   20056.340659  0.953148   \n",
      "9                  KNN (k=8)   14533.942434   21419.852564  0.951832   \n",
      "10                 KNN (k=9)   16367.517544   21635.527066  0.950381   \n",
      "11                KNN (k=10)   17739.892763   21471.817949  0.952848   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          2.649801e-07             9.415775e-12       2.100235  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.hitachi_construction_machinery_co_ltd_6305_t': {'Model': 'KNN (k=3)', 'MAE Train': 7034.168859649122, 'MAE Test': 13727.49572649573, 'R² Test': 0.960603421752737, 'Top Features': construction_cost_prices_sales.public_and_housing_associations    0.004242\n",
      "uk_building.local_authorities                                     0.003676\n",
      "uk_retail_price.london                                            0.003636\n",
      "uk_retail_price.index_of_private_housing_rental_prices            0.003636\n",
      "uk_retail_price.england                                           0.003636\n",
      "uk_retail_price.south_east_england                                0.003592\n",
      "uk_retail_price.wales                                             0.003592\n",
      "uk_building.building_housing_starts                               0.003547\n",
      "mortage_interest_rate.2_years5                                    0.003547\n",
      "uk_retail_price.south_west_england                                0.003474\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.j_c_bamford_excavators_ltd_4296370337\n",
      "  (                       Model    MAE Train     MAE Test   R² Test  \\\n",
      "0          Linear Regression    79.641728   194.807881  0.987161   \n",
      "1              Random Forest    35.608897   109.471686  0.960717   \n",
      "2          Gradient Boosting    15.323574   105.520268  0.954830   \n",
      "3   Support Vector Regressor  1173.287614  1262.629480  0.031619   \n",
      "4                  KNN (k=3)    42.162719    92.486325  0.961412   \n",
      "5                  KNN (k=4)    51.413651   110.893590  0.957213   \n",
      "6                  KNN (k=5)    59.318553   112.430769  0.957668   \n",
      "7                  KNN (k=6)    72.965789   135.236325  0.961167   \n",
      "8                  KNN (k=7)    82.358083   129.453114  0.967194   \n",
      "9                  KNN (k=8)    98.002220   137.726603  0.967593   \n",
      "10                 KNN (k=9)   111.840351   139.492877  0.968135   \n",
      "11                KNN (k=10)   122.238553   139.199231  0.970900   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0              0.000699             1.251046e-09       2.142646  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.j_c_bamford_excavators_ltd_4296370337': {'Model': 'KNN (k=3)', 'MAE Train': 42.162719298245655, 'MAE Test': 92.48632478632481, 'R² Test': 0.9614116444675961, 'Top Features': uk_building.local_authorities                                                            0.005226\n",
      "construction_cost_prices_sales.other_private_industrial_work_excluding_infrastructure    0.004676\n",
      "construction_cost_prices_sales.public_and_housing_associations                           0.004534\n",
      "uk_retail_price.london                                                                   0.002600\n",
      "uk_retail_price.england                                                                  0.002600\n",
      "uk_retail_price.index_of_private_housing_rental_prices                                   0.002600\n",
      "uk_retail_price.wales                                                                    0.002600\n",
      "uk_retail_price.south_east_england                                                       0.002600\n",
      "uk_building.building_housing_starts                                                      0.002599\n",
      "mortage_interest_rate.2_years5                                                           0.002599\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.komatsu_ltd_6301_t\n",
      "  (                       Model      MAE Train       MAE Test   R² Test  \\\n",
      "0          Linear Regression   32308.808991   89001.041888  0.984850   \n",
      "1              Random Forest   13891.301135   50884.819731  0.959028   \n",
      "2          Gradient Boosting    6549.310228   50058.024848  0.954610   \n",
      "3   Support Vector Regressor  425218.302088  479305.839736 -0.085339   \n",
      "4                  KNN (k=3)   19029.195175   47368.931624  0.955217   \n",
      "5                  KNN (k=4)   22903.212171   53397.698718  0.952052   \n",
      "6                  KNN (k=5)   27273.586842   54990.405128  0.952615   \n",
      "7                  KNN (k=6)   32497.547149   63633.106838  0.954102   \n",
      "8                  KNN (k=7)   35968.975564   61434.238095  0.957547   \n",
      "9                  KNN (k=8)   42434.818257   64855.490385  0.958216   \n",
      "10                 KNN (k=9)   47528.853070   65953.840456  0.956934   \n",
      "11                KNN (k=10)   51240.001316   64495.848718  0.960499   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          9.038018e-08             1.217381e-13       2.108144  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.komatsu_ltd_6301_t': {'Model': 'KNN (k=3)', 'MAE Train': 19029.195175438595, 'MAE Test': 47368.931623931625, 'R² Test': 0.9552166167459758, 'Top Features': construction_cost_prices_sales.other_private_industrial_work_excluding_infrastructure    0.004069\n",
      "uk_building.local_authorities                                                            0.002864\n",
      "construction_cost_prices_sales.housing3                                                  0.001892\n",
      "construction_cost_prices_sales.public_and_housing_associations                           0.001617\n",
      "construction_cost_prices_sales.other_public_work_excluding_infrastructure                0.001419\n",
      "construction_cost_prices_sales.infrastructure2                                           0.001181\n",
      "uk_retail_price.england                                                                  0.001162\n",
      "uk_retail_price.index_of_private_housing_rental_prices                                   0.001162\n",
      "uk_retail_price.london                                                                   0.001162\n",
      "uk_retail_price.south_east_england                                                       0.001146\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.liebherr_international_ltd_4298321885\n",
      "  (                       Model    MAE Train     MAE Test   R² Test  \\\n",
      "0          Linear Regression    85.203082   267.942122  0.986448   \n",
      "1              Random Forest    53.121468   147.997162  0.976618   \n",
      "2          Gradient Boosting    28.896059   124.905666  0.972511   \n",
      "3   Support Vector Regressor  1380.923533  1421.597627 -0.151349   \n",
      "4                  KNN (k=3)    70.732456   124.564103  0.980765   \n",
      "5                  KNN (k=4)    81.842105   150.301282  0.975338   \n",
      "6                  KNN (k=5)    96.836842   153.676923  0.975252   \n",
      "7                  KNN (k=6)   116.547149   198.982906  0.969237   \n",
      "8                  KNN (k=7)   124.387218   203.699634  0.967910   \n",
      "9                  KNN (k=8)   136.070724   217.432692  0.965716   \n",
      "10                 KNN (k=9)   151.442982   217.276353  0.967130   \n",
      "11                KNN (k=10)   165.234868   216.900000  0.968668   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          3.373286e-13             9.412778e-11       2.029226  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.liebherr_international_ltd_4298321885': {'Model': 'KNN (k=3)', 'MAE Train': 70.73245614035088, 'MAE Test': 124.56410256410251, 'R² Test': 0.9807654483745106, 'Top Features': uk_retail_price.south_west_england                        0.005382\n",
      "uk_retail_price.index_of_private_housing_rental_prices    0.005285\n",
      "uk_retail_price.london                                    0.005285\n",
      "uk_retail_price.england                                   0.005285\n",
      "uk_retail_price.south_east_england                        0.005146\n",
      "uk_retail_price.wales                                     0.005146\n",
      "uk_building.building_housing_starts                       0.005007\n",
      "mortage_interest_rate.2_years5                            0.005007\n",
      "uk_building.local_authorities                             0.004957\n",
      "uk_retail_price.yorkshire_and_humberside                  0.004826\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.speedy_hire_plc_sdy_l\n",
      "  (                       Model  MAE Train   MAE Test   R² Test  \\\n",
      "0          Linear Regression   3.713670  11.394265  0.922449   \n",
      "1              Random Forest   2.156854   9.781439  0.763317   \n",
      "2          Gradient Boosting   1.083442   8.633968  0.741401   \n",
      "3   Support Vector Regressor  12.725664  21.821015  0.261120   \n",
      "4                  KNN (k=3)   2.564474   9.270085  0.739645   \n",
      "5                  KNN (k=4)   2.958224   9.722436  0.721660   \n",
      "6                  KNN (k=5)   3.564342  10.362564  0.711034   \n",
      "7                  KNN (k=6)   4.010526  11.650855  0.691658   \n",
      "8                  KNN (k=7)   4.273966  11.555678  0.687020   \n",
      "9                  KNN (k=8)   4.719737  12.183974  0.675308   \n",
      "10                 KNN (k=9)   5.347880  12.394302  0.667432   \n",
      "11                KNN (k=10)   5.837105  12.304103  0.692845   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0              0.000001             1.618806e-11       2.190148  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.speedy_hire_plc_sdy_l': {'Model': 'Gradient Boosting', 'MAE Train': 1.083441946475456, 'MAE Test': 8.633968204349252, 'R² Test': 0.7414010881571873, 'Top Features': cpi.cpi                                           0.224387\n",
      "mortage.monetary_financial_institutions           0.165067\n",
      "mortage.all_lenders_gbp                           0.065417\n",
      "cpi.cpi_annual_growth_rate                        0.062822\n",
      "unemployment_rate.unenployment_rate               0.057301\n",
      "construction_cost_prices_sales.infrastructure2    0.055337\n",
      "money_supply.m1                                   0.053743\n",
      "uk_retail_price.wales                             0.051516\n",
      "mortage.house_purchase                            0.050740\n",
      "money_supply.m2_yoy_growth_rate                   0.038533\n",
      "dtype: float64}})\n",
      "Data is normalized\n",
      "⚠️ Dimension mismatch for Linear Regression: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Random Forest: 83 importances vs 77 features\n",
      "⚠️ Dimension mismatch for Gradient Boosting: 83 importances vs 77 features\n",
      "y: operating_expenses.terex_corp_tex\n",
      "  (                       Model    MAE Train    MAE Test   R² Test  \\\n",
      "0          Linear Regression    64.191836  378.992461  0.990338   \n",
      "1              Random Forest    32.855972  283.053398  0.710030   \n",
      "2          Gradient Boosting    17.590533  245.349547  0.756744   \n",
      "3   Support Vector Regressor  1127.657485  947.654660 -0.076790   \n",
      "4                  KNN (k=3)    39.864474  280.429060  0.703570   \n",
      "5                  KNN (k=4)    44.529441  296.033974  0.683157   \n",
      "6                  KNN (k=5)    52.103289  304.287692  0.672191   \n",
      "7                  KNN (k=6)    61.663925  315.830769  0.679959   \n",
      "8                  KNN (k=7)    68.924718  309.705495  0.690121   \n",
      "9                  KNN (k=8)    78.344572  319.199679  0.681842   \n",
      "10                 KNN (k=9)    85.186842  323.378348  0.685678   \n",
      "11                KNN (k=10)    94.344079  311.971795  0.732168   \n",
      "\n",
      "    Shapiro-W (p-value)  Breusch-Pagan (p-value)  Durbin-Watson  \n",
      "0          1.647612e-09             4.928220e-25       1.865384  \n",
      "1                   NaN                      NaN            NaN  \n",
      "2                   NaN                      NaN            NaN  \n",
      "3                   NaN                      NaN            NaN  \n",
      "4                   NaN                      NaN            NaN  \n",
      "5                   NaN                      NaN            NaN  \n",
      "6                   NaN                      NaN            NaN  \n",
      "7                   NaN                      NaN            NaN  \n",
      "8                   NaN                      NaN            NaN  \n",
      "9                   NaN                      NaN            NaN  \n",
      "10                  NaN                      NaN            NaN  \n",
      "11                  NaN                      NaN            NaN  , {'operating_expenses.terex_corp_tex': {'Model': 'Gradient Boosting', 'MAE Train': 17.590532951854176, 'MAE Test': 245.34954732118217, 'R² Test': 0.7567435893736908, 'Top Features': unemployment_rate.unenployment_rate                                                      0.667228\n",
      "money_supply.m1                                                                          0.208656\n",
      "mortage_interest_rate.5_years3                                                           0.049746\n",
      "money_supply.m2                                                                          0.028409\n",
      "cpi.cpi                                                                                  0.018779\n",
      "money_supply.m3                                                                          0.005827\n",
      "extra_unemployment_rate.male                                                             0.004206\n",
      "seasonal_retail_sales.revenue                                                            0.002324\n",
      "seasonal_retail_sales.retail_sale_volume_index                                           0.001759\n",
      "construction_cost_prices_sales.other_private_industrial_work_excluding_infrastructure    0.001415\n",
      "dtype: float64}})\n"
     ]
    }
   ],
   "source": [
    "for i in dependent_vars:\n",
    "    resultats = regression_analysis(df, i, X)\n",
    "    print(f'y: {i}\\n ', resultats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
